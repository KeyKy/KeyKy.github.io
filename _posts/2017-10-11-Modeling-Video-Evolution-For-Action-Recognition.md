---
layout: post
title: Modeling Video Evolution For Action Recognition
---

## Abstract

æœ¬æ–‡å±•ç¤ºäº†ä¸€ç§èƒ½å¤Ÿæ•è·è§†é¢‘æ—¶åºä¿¡æ¯çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å‡å®šèƒ½æ—¶åºæ€§æ’åºè§†é¢‘å¸§çš„å‡½æ•°(a function capable of ording the frames of a video)ä¹Ÿèƒ½éå¸¸å¥½çš„æ•è·è§†é¢‘ä¸­è§†è§‰ä¸Šçš„æ¼”å˜(evolution of the appearance within the video)ã€‚å› æ­¤æœ¬æ–‡çš„é‡ç‚¹æ˜¯ï¼Œä½œè€…é€šè¿‡ä½¿ç”¨ranking machineå­¦ä¹ è¿™æ ·çš„æ’åºå‡½æ•°å¹¶ä¸”ä½¿ç”¨å…¶å¯¹åº”çš„å‚æ•°ä½œä¸ºä¸€ä¸ªæ–°çš„è§†é¢‘è¡¨å¾ã€‚å¹¶åœ¨é€šç”¨åŠ¨ä½œè¯†åˆ«æ•°æ®é›†Hollywood2ã€HMDB51ã€ç»†é¢—ç²’åº¦çš„åŠ¨ä½œMPII-cooking activitieså’Œå§¿åŠ¿æ•°æ®é›†Chalearnä¸­æœ‰7%-10%çš„æå‡ã€‚åŒæ—¶è¯¥æ–¹æ³•æ˜¯ä¸€ç§å¯¹è§†é¢‘è§†è§‰ç‰¹å¾çš„ç¼–ç ï¼Œç‹¬ç«‹äºç‰¹å¾æå–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´è§†è§‰ç‰¹å¾æå–æ–¹æ³•è¶Šå¥½ï¼Œç¼–ç åå¯¹è§†é¢‘åŠ¨ä½œè¯†åˆ«æ•ˆæœä¹Ÿèƒ½ç›¸åº”æœ‰æå‡ã€‚

## Introduction

æœ¬æ–‡è¯´åœ¨è¿‡å»åå¹´åŠ¨ä½œè¯†åˆ«çš„ç ”ç©¶ä¸»è¦æ˜¯åœ¨è®¾è®¡æ—¶é—´ç©ºé—´(spatio-temporal)çš„ç‰¹å¾ï¼š

  * from temporal interest points over dense sampling to dense trajectories.
  	  * [On space-time interest points]
  	  * [Learning realistic human actions from movies]
  	  * [Dense trajectories and motion boundary descriptors for action recognition]
  * from gradient-based descriptors to motion-based and motion-compensated ones.
  	  * [Better exploiting motion for better action recognition]
  * adoption of powerful encoding schemes, Fisher Vectors.
  	  * [Action recognition with improved trajectories]

æœ¬æ–‡è¿˜æåˆ°ä»è§†è§‰ä¸Šå»ºæ¨¡æ—¶åºçš„æ¼”å˜ä¿¡æ¯æ¯”è¾ƒå›°éš¾ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†å¾ˆå¤šæ–¹æ³•å»ºæ¨¡æ—¶åºä¿¡æ¯ï¼šHMMï¼ŒCRFç­‰ï¼Œå…·ä½“çœ‹è®ºæ–‡ã€‚

Modeling the video-wide temporal evolution of appearance in videos remains a challenging task, due to the large variability and complexity of video data. Actions are performed at largely varying speeds. Also the speed of the action often varies non-linearly within a single video.

æœ¬æ–‡å¯¹æ—¶åºä¿¡æ¯çš„å»ºæ¨¡æ€è·¯çš„æœ¬è´¨æ¥æºæ˜¯ï¼š

Nevertheless, it is clear that many actions have a characteristic temporal ordering. More precisely, given all the frames
of the video, we learn how to arrange them in chronological order, based on the content of the frames.

<img src='../images/Modeling-Video-Evolution-For-Action-Recognition/1.png' width='400'>

## Related work

ç•¥...

## Modeling Video-wide temporal evolution (VideoDarwin)

1. Video X = [x_1, x_2, ..., x_3] composed of ğ‘› frames and frame at ğ‘¡ is represented by vector.
2. Define a vector valued function ğ‘‰. The output of the vector valued function v_t is obtained by processing all the frames
up to time ğ‘¡, x_1:t. For example, the vector v_t can be obtained by applying the mean operation on all of the frames x_1:t.
3. Define ğœ“(v; u) = uğ‘‡ â‹… v. 
4. Namely, the learning to rank problem optimizes the parameters u of the function ğœ“(v; u), such that âˆ€ğ‘–, ğ‘— , v_i â‰» v_j â‡â‡’ uğ‘‡ â‹…v_i > uğ‘‡ â‹…v_j.

è¿™é‡Œçš„æ€æƒ³æ˜¯æ‰¾åˆ°ä¸€ä¸ªå‘é‡u,ä½¿å¾—v_iå’Œv_jåœ¨è¯¥æ–¹å‘ä¸Šçš„æŠ•å½±ä»ç„¶æ»¡è¶³æ—¶åºæ’åºï¼Œé‚£ä¹ˆè¯¥å‘é‡å°±èƒ½è¡¨å¾æ—¶åºä¸Šçš„æ¼”å˜ï¼Œä¹Ÿèƒ½æŠŠè®¸å¤šå¸§ç”¨ä¸€ä¸ªå‘é‡è¡¨ç¤ºã€‚è®ºæ–‡ä¸­ç»™å‡ºäº†å‘é‡uçš„ä¼˜åŒ–æ±‚æ³•ï¼Œæ®è®ºæ–‡æ‰€è¿°æ˜¯ä½¿ç”¨RankSVMï¼š

<img src='../images/Modeling-Video-Evolution-For-Action-Recognition/2.png' width='400'>



## Experiments


## Conclusion


## References
