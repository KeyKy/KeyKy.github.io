---
layout: post
title: Modeling Video Evolution For Action Recognition
---

## Abstract

æœ¬æ–‡å±•ç¤ºäº†ä¸€ç§èƒ½å¤Ÿæ•è·è§†é¢‘æ—¶åºä¿¡æ¯çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å‡å®šèƒ½æ—¶åºæ€§æ’åºè§†é¢‘å¸§çš„å‡½æ•°(a function capable of ording the frames of a video)ä¹Ÿèƒ½éå¸¸å¥½çš„æ•è·è§†é¢‘ä¸­è§†è§‰ä¸Šçš„æ¼”å˜(evolution of the appearance within the video)ã€‚å› æ­¤æœ¬æ–‡çš„é‡ç‚¹æ˜¯ï¼Œä½œè€…é€šè¿‡ä½¿ç”¨ranking machineå­¦ä¹ è¿™æ ·çš„æ’åºå‡½æ•°å¹¶ä¸”ä½¿ç”¨å…¶å¯¹åº”çš„å‚æ•°ä½œä¸ºä¸€ä¸ªæ–°çš„è§†é¢‘è¡¨å¾ã€‚å¹¶åœ¨é€šç”¨åŠ¨ä½œè¯†åˆ«æ•°æ®é›†Hollywood2ã€HMDB51ã€ç»†é¢—ç²’åº¦çš„åŠ¨ä½œMPII-cooking activitieså’Œå§¿åŠ¿æ•°æ®é›†Chalearnä¸­æœ‰7%-10%çš„æå‡ã€‚åŒæ—¶è¯¥æ–¹æ³•æ˜¯ä¸€ç§å¯¹è§†é¢‘è§†è§‰ç‰¹å¾çš„ç¼–ç ï¼Œç‹¬ç«‹äºç‰¹å¾æå–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´è§†è§‰ç‰¹å¾æå–æ–¹æ³•è¶Šå¥½ï¼Œç¼–ç åå¯¹è§†é¢‘åŠ¨ä½œè¯†åˆ«æ•ˆæœä¹Ÿèƒ½ç›¸åº”æœ‰æå‡ã€‚

## Introduction

æœ¬æ–‡è¯´åœ¨è¿‡å»åå¹´åŠ¨ä½œè¯†åˆ«çš„ç ”ç©¶ä¸»è¦æ˜¯åœ¨è®¾è®¡æ—¶é—´ç©ºé—´(spatio-temporal)çš„ç‰¹å¾ï¼š

  * from temporal interest points over dense sampling to dense trajectories.
  	  * [On space-time interest points]
  	  * [Learning realistic human actions from movies]
  	  * [Dense trajectories and motion boundary descriptors for action recognition]
  * from gradient-based descriptors to motion-based and motion-compensated ones.
  	  * [Better exploiting motion for better action recognition]
  * adoption of powerful encoding schemes, Fisher Vectors.
  	  * [Action recognition with improved trajectories]

æœ¬æ–‡è¿˜æåˆ°ä»è§†è§‰ä¸Šå»ºæ¨¡æ—¶åºçš„æ¼”å˜ä¿¡æ¯æ¯”è¾ƒå›°éš¾ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†å¾ˆå¤šæ–¹æ³•å»ºæ¨¡æ—¶åºä¿¡æ¯ï¼šHMMï¼ŒCRFç­‰ï¼Œå…·ä½“çœ‹è®ºæ–‡ã€‚

Modeling the video-wide temporal evolution of appearance in videos remains a challenging task, due to the large variability and complexity of video data. Actions are performed at largely varying speeds. Also the speed of the action often varies non-linearly within a single video.

æœ¬æ–‡å¯¹æ—¶åºä¿¡æ¯çš„å»ºæ¨¡æ€è·¯çš„æœ¬è´¨æ¥æºæ˜¯ï¼š

Nevertheless, it is clear that many actions have a characteristic temporal ordering. More precisely, given all the frames
of the video, we learn how to arrange them in chronological order, based on the content of the frames.

<img src='../images/Modeling-Video-Evolution-For-Action-Recognition/1.png' width='600'>

## Related work

ç•¥...

## Modeling Video-wide temporal evolution (VideoDarwin)

1. Video X = [x_1, x_2, ..., x_3] composed of ğ‘› frames and frame at ğ‘¡ is represented by vector.
2. Define a vector valued function ğ‘‰. The output of the vector valued function v_t is obtained by processing all the frames
up to time ğ‘¡, x_1:t. For example, the vector v_t can be obtained by applying the mean operation on all of the frames x_1:t.
3. Define ğœ“(v; u) = u^ğ‘‡ â‹… v. 
4. Namely, the learning to rank problem optimizes the parameters u of the function ğœ“(v; u), such that âˆ€ğ‘–, ğ‘— , v_i â‰» v_j â‡â‡’ u^ğ‘‡ â‹…v_i > u^ğ‘‡ â‹…v_j.

è¿™é‡Œçš„æ€æƒ³æ˜¯æ‰¾åˆ°ä¸€ä¸ªå‘é‡u,ä½¿å¾—v_iå’Œv_jåœ¨è¯¥æ–¹å‘ä¸Šçš„æŠ•å½±ä»ç„¶æ»¡è¶³æ—¶åºæ’åºï¼Œé‚£ä¹ˆè¯¥å‘é‡å°±èƒ½è¡¨å¾æ—¶åºä¸Šçš„æ¼”å˜ï¼Œä¹Ÿèƒ½æŠŠè®¸å¤šå¸§ç”¨ä¸€ä¸ªå‘é‡è¡¨ç¤ºã€‚è®ºæ–‡ä¸­ç»™å‡ºäº†å‘é‡uçš„ä¼˜åŒ–æ±‚æ³•ï¼Œæ®è®ºæ–‡æ‰€è¿°æ˜¯ä½¿ç”¨RankSVMï¼Œ

<img src='../images/Modeling-Video-Evolution-For-Action-Recognition/2.png' width='450'>

æ¡ä»¶1ï¼Œu^ğ‘‡ â‹… (v\_ti âˆ’ v\_tj ) â‰¥ 1 âˆ’ ğœ–\_ğ‘–ğ‘—ï¼Œå³æ˜¯è¦æ»¡è¶³æ’åºæ¡ä»¶å¤§äºä¸€ä¸ªå•ä½é‡å¹¶ä¸”æœ‰ä¸€ä¸ªæ¾å¼›å› å­ï¼Œå¦‚æœæ¾å¼›å› å­è¿‡å¤§ä¼šæƒ©ç½šä¼˜åŒ–å‡½æ•°ã€‚åœ¨ä½œè€…çš„å¼€æºä»£ç (VideoDarwin.m)ä¸­ä½œè€…æ˜¯é€šè¿‡SVRæ¥è§£å†³æ’åºé—®é¢˜ï¼Œæ—¢ç»™æ¯ä¸€å¸§èµ‹äºˆä¸€ä¸ªlabelï¼Œæ¯”å¦‚ç¬¬ä¸€å¸§çš„labelæ˜¯1ï¼Œç¬¬äºŒå¸§æ˜¯2ï¼Œä¾æ¬¡ç±»æ¨...ç„¶åè®­ç»ƒä¸€ä¸ªSVRå›å½’æ¨¡å‹æ±‚å¾—æƒé‡å‘é‡uã€‚å…¶å®æœ€ç®€å•çš„å°±æ˜¯ç”¨çº¿æ€§å›å½’è¿›è¡Œæ±‚è§£ï¼Œåœ¨è®ºæ–‡ä¸­ä¹Ÿè¡¨ç¤ºè¿™æ ·ä¹Ÿæ˜¯å¯è¡Œçš„(any other linear learning to rank method can be employed to learn VideoDarwin)ã€‚

## Vector valued functions for VideoDarwin

è¿™èŠ‚ä¸»è¦æ˜¯æåŠä¸Šé¢æ²¡æœ‰è§£é‡Šçš„å‘é‡ä»·å€¼å‡½æ•°Vçš„é€‰å–ï¼Œè®ºæ–‡ä¸­æ¢å¯»äº†3ç§å½¢å¼çš„å‘é‡ä»·å€¼å‡½æ•°ï¼š

1. Independent Frame Representation. <!-- V(t) = x_t / ||x_t|| . -->
2. Moving Average (MA). <!--\sum_t:t+T { x_t }  -->.
3. Time Varying Mean Vectors.  <!--m_t = 1/t * \sum_1:t { x_i }, v_t = m_t / ||m_t|| .-->

ä½œè€…é€šè¿‡å®éªŒè¯æ˜ç¬¬ä¸‰ç§æ–¹å¼æ•ˆæœæœ€å¥½ã€‚

<img src='../images/Modeling-Video-Evolution-For-Action-Recognition/3.png' width='450'>

## Experiments



## Conclusion


## References
