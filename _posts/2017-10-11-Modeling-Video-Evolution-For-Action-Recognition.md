---
layout: post
title: Modeling Video Evolution For Action Recognition
---

## Abstract

æœ¬æ–‡å±•ç¤ºäº†ä¸€ç§èƒ½å¤Ÿæ•è·è§†é¢‘æ—¶åºä¿¡æ¯çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å‡å®šèƒ½æ—¶åºæ€§æ’åºè§†é¢‘å¸§çš„å‡½æ•°(a function capable of ording the frames of a video)ä¹Ÿèƒ½éå¸¸å¥½çš„æ•è·è§†é¢‘ä¸­è§†è§‰ä¸Šçš„æ¼”å˜(evolution of the appearance within the video)ã€‚å› æ­¤æœ¬æ–‡çš„é‡ç‚¹æ˜¯ï¼Œä½œè€…é€šè¿‡ä½¿ç”¨ranking machineå­¦ä¹ è¿™æ ·çš„æ’åºå‡½æ•°å¹¶ä¸”ä½¿ç”¨å…¶å¯¹åº”çš„å‚æ•°ä½œä¸ºä¸€ä¸ªæ–°çš„è§†é¢‘è¡¨å¾ã€‚å¹¶åœ¨é€šç”¨åŠ¨ä½œè¯†åˆ«æ•°æ®é›†Hollywood2ã€HMDB51ã€ç»†é¢—ç²’åº¦çš„åŠ¨ä½œMPII-cooking activitieså’Œå§¿åŠ¿æ•°æ®é›†Chalearnä¸­æœ‰7%-10%çš„æå‡ã€‚åŒæ—¶è¯¥æ–¹æ³•æ˜¯ä¸€ç§å¯¹è§†é¢‘è§†è§‰ç‰¹å¾çš„ç¼–ç ï¼Œç‹¬ç«‹äºç‰¹å¾æå–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´è§†è§‰ç‰¹å¾æå–æ–¹æ³•è¶Šå¥½ï¼Œç¼–ç åå¯¹è§†é¢‘åŠ¨ä½œè¯†åˆ«æ•ˆæœä¹Ÿèƒ½ç›¸åº”æœ‰æå‡ã€‚

## Introduction

æœ¬æ–‡è¯´åœ¨è¿‡å»åå¹´åŠ¨ä½œè¯†åˆ«çš„ç ”ç©¶ä¸»è¦æ˜¯åœ¨è®¾è®¡æ—¶é—´ç©ºé—´(spatio-temporal)çš„ç‰¹å¾ï¼š

  * from temporal interest points over dense sampling to dense trajectories.
  	* [On space-time interest points]
  	* [Learning realistic human actions from movies]
  	* [Dense trajectories and motion boundary descriptors for action recognition]
  * from gradient-based descriptors to motion-based and motion-compensated ones.
  	* [Better exploiting motion for better action recognition]
  * adoption of powerful encoding schemes, Fisher Vectors.
  	* [Action recognition with improved trajectories]

æœ¬æ–‡è¿˜æåˆ°ä»è§†è§‰ä¸Šå»ºæ¨¡æ—¶åºçš„æ¼”å˜ä¿¡æ¯æ¯”è¾ƒå›°éš¾ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†å¾ˆå¤šæ–¹æ³•å»ºæ¨¡æ—¶åºä¿¡æ¯ï¼šHMMï¼ŒCRFç­‰ï¼Œå…·ä½“çœ‹è®ºæ–‡ã€‚

Modeling the video-wide temporal evolution of appearance in videos remains a challenging task, due to the large variability and complexity of video data. Actions are performed at largely varying speeds. Also the speed of the action often varies non-linearly within a single video.

æœ¬æ–‡å¯¹æ—¶åºä¿¡æ¯çš„å»ºæ¨¡æ€è·¯çš„æœ¬è´¨æ¥æºæ˜¯ï¼š

Nevertheless, it is clear that many actions have a characteristic temporal ordering. More precisely, given all the frames
of the video, we learn how to arrange them in chronological order, based on the content of the frames.

## Related work

ç•¥...

## Modeling Video-wide temporal evolution (VideoDarwin)

1. Video X = [x_1, x_2, ..., x_3] composed of ğ‘› frames and frame at ğ‘¡ is represented by vector.





## Experiments


## Conclusion


## References
